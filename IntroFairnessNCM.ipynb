{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hhaller0826/ci2-fairness-ncm/blob/main/IntroFairnessNCM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgunRRxRSECt"
      },
      "source": [
        "# Introduction/Explanation\n",
        "\n",
        "Causal Inference can be a powerful tool for analyzing relationships between variables and generating explanations for observed phenomena. Neural causal models are a tool which allow its wielder to answer questions about causality using domain knowledge and observational data [Xia et. al.](https://causalai.net/r87.pdf). Causal fairness analysis is a framework for using these causal questions to make scientific claims about bias and discrimination [Pleƒçko et. al.](https://causalai.net/r90.pdf). This notebook introduces a user-friendly framework for performing causal fairness analysis using\n",
        "neural causal models\n",
        "\n",
        "---\n",
        "\n",
        "### Table of Contents\n",
        "**Section 1: Create a Causal Graph** \n",
        "This will walk you through creating a graph to represent relationships between the variables you plan to analyze. \n",
        "\n",
        "**Section 2: Train the Model**\n",
        "This will walk you through creating a neural causal model, and training it to learn the relationships that are represented in your causal graph based on your data.\n",
        "\n",
        "**Section 3: Extract Causal Insights from the Model**\n",
        "This will provide instructions for extracting information about the causal relationships in your trained model. This may contain useful tools for your analysis, but does not contain any steps that are necessary for progressing to Section 4.\n",
        "\n",
        "**Section 4: Project onto the Standard Fairness Model**\n",
        "This will walk you through projecting your trained model onto a standard fairness model, which can then be used to perform fairness analysis. Note that the tools for extracting metrics described in Section 3 can also be applied to the resulting standard fairness model. \n",
        "\n",
        "**Section 5: Run Fairness Tasks** \n",
        "This will walk you through using your Standard Fairness Model projection to perform bias detection, fair prediction, and fair decision-making."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this cell before you progress to ensure this notebook has access to the necessary code.\n",
        "import pandas as pd\n",
        "from src.utilities import *\n",
        "from src.graph.utils import *\n",
        "from src.graph.causal_graph import CausalGraph\n",
        "from src.training.train import *\n",
        "from src.metric.probabilities import ReusableProbability\n",
        "from src.metric.queries import *\n",
        "from src.model.sfm import SFM\n",
        "from src.fairness.task1 import FairnessCookbook\n",
        "from src.fairness.task2 import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj1bp-5ESFoq"
      },
      "source": [
        "# Create a Causal Graph\n",
        "\n",
        "A causal graph (or \"causal diagram\") represents the relationships between the features in your data. Each node on the graph may represent one or more of these features, though the name of the node does *not* need to correspond to the data column that it will represent. Please note that if a single node represents multiple features, we will not be able to distinguish between these features when doing causal analysis. \n",
        "\n",
        "If the values in one node may cause or impact the values in another node, the graph will have a directed edge from the first node to the one that it affects. A directed edge reflects a belief, based on theory, data, or domain knowledge, that changes in the source variable can produce changes in the destimation variable.\n",
        "\n",
        "Sometimes there are confounders between two variables (lets call them A and B), meaning they are both directly impacted by the same third variable C. If C is one of the nodes on your graph, then there will be one directed edge from C to A, and another from C to B. If C is *not* one of the nodes on your graph, indicating that C may represent a feature which was not recorded in your data, then we will create a bi-directed edge between A and B to signify that they are confounded. \n",
        "\n",
        "Directed edges are represented by a solid-line arrow from the source node to the destination node. Bidirected edges are represented by a dotted double-sided arrow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define your graph below.\n",
        "\n",
        "You can use one of the pre-defined graphs, like so:\n",
        "```\n",
        "my_graph = get_predefined_graph(type='____')\n",
        "```\n",
        "Valid types include `simple`, `bow`, `frontdoor`, `backdoor`, `napkin`, and `sfm`. \n",
        "\n",
        "![](img/default_graphs.png)\n",
        "\n",
        "Alternatively, you create your own graph. You must define a `CausalGraph` object with a list of all the nodes in your graph, a list of all the bidirected edges in your graph, and a list of directed edges in your graph. When defining the directed edges, the arrow goes from the first node to the second one. So ```directed_edges = [('X', 'Y')]``` indicates one edge going from 'X' to 'Y'. When defining a bidirected edge, it does not matter which direction nodes are listed.\n",
        "\n",
        "Here is an example:\n",
        "```\n",
        "nodes = ['W', 'X', 'Y', 'Z']\n",
        "bidirected_edges = [('X', 'Z'), ('Z', 'Y')]\n",
        "directed_edges = [\n",
        "    ('X', 'Y'),\n",
        "    ('X', 'W'),\n",
        "    ('Z', 'Y'),\n",
        "    ('Z', 'W'),\n",
        "    ('W', 'Y')\n",
        "]\n",
        "\n",
        "my_graph = CausalGraph(nodes, directed_edges, bidirected_edges)\n",
        "```\n",
        "<img src=\"img/custom_graph_ex.png\" alt=\"GraphEx\" style=\"width: 200px;\"/>\n",
        "\n",
        "\n",
        "\n",
        "##### <span style=\"text-decoration:underline\">Summary of Graph Requirements:</span>\n",
        "* This graph will represent relationships between features in your data.\n",
        "    * Names of the nodes are not important. Later in the notebook you will specify which nodes should be associated with which features of your data.\n",
        "    * If a single node represents multiple data features, those features will be treated as a single unit. We can determine causal relationships between that set of features and another set of features, but we will not be able to distinguish how the features are behaving unless they are assigned to their own node.  \n",
        "* A directed edge indicates that changes in one variable may change the value of another variable.\n",
        "    * ```directed_edges = [('X', 'Y')]``` will create an arrow $X\\rightarrow Y$ in your graph.\n",
        "* A bidirected edge indicates that an outside force may be influencing two variables within the graph, which may cause the two to be correlated (even if there is no causal relationship between them).\n",
        "    * ```bidirected_edges = [('X', 'Y')]``` is the same as ```bidirected_edges = [('Y', 'X')]``` and will create a dotted arrow $X\\leftrightarrow Y$ in your graph.\n",
        "* The absence of an edge is more important than the presence of an edge. Much of causal inference is determining whether something has an affect on another thing, so it is possible that we will learn that there is no real relationship between two variables, even if they are connected by an arrow. We will not be able to study the relationship between them without an arrow. *However*...\n",
        "* **The graph must be acyclic**. This means that there cannot be a path of *directed* arrows forming a loop. \n",
        "    * If you have a directed edge $A\\rightarrow B$, then you cannot have a directed edge $B\\rightarrow A$. More generally, if there is a path $A\\rightarrow B\\rightarrow ...\\rightarrow Z$, then there can be no path $Z\\rightarrow ...\\rightarrow A$.\n",
        "    * Path restrictions do not apply to bidirected arrows. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTION 1 -- using a pre-defined graph:\n",
        "my_graph = get_predefined_graph('backdoor')\n",
        "\n",
        "# OPTION 2 -- using a custom graph (delete this if you pick option 1): \n",
        "nodes = ['A', 'B', 'C', 'D', 'E', 'F', 'G'] # Node names do not need to correspond to the names of your data columns. \n",
        "bidirected_edges = [\n",
        "    ('C', 'A'),\n",
        "    ('C', 'F'),\n",
        "    ('F', 'A'),\n",
        "]\n",
        "directed_edges = [\n",
        "    ('A', 'B'),\n",
        "    ('A', 'D'),\n",
        "    ('A', 'E'),\n",
        "    ('A', 'G'),\n",
        "    ('C', 'B'),\n",
        "    ('C', 'D'),\n",
        "    ('C', 'E'),\n",
        "    ('C', 'G'),\n",
        "    ('F', 'B'),\n",
        "    ('F', 'D'),\n",
        "    ('F', 'E'),\n",
        "    ('F', 'G'),\n",
        "    ('D', 'B'),\n",
        "    ('D', 'G'),\n",
        "    ('E', 'B'),\n",
        "    ('E', 'G'),\n",
        "]\n",
        "\n",
        "my_graph = CausalGraph(nodes, directed_edges, bidirected_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Double-check that this is the graph you want:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
              " -->\n",
              "<!-- Title: G Pages: 1 -->\n",
              "<svg width=\"267pt\" height=\"255pt\"\n",
              " viewBox=\"0.00 0.00 267.30 254.58\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 250.58)\">\n",
              "<title>G</title>\n",
              "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-250.58 263.3,-250.58 263.3,4 -4,4\"/>\n",
              "<!-- F -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>F</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"232.3\" cy=\"-123.29\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"232.3\" y=\"-118.24\" font-family=\"Times,serif\" font-size=\"14.00\">F</text>\n",
              "</g>\n",
              "<!-- A -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>A</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"100.27\" cy=\"-228.58\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"100.27\" y=\"-223.53\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n",
              "</g>\n",
              "<!-- F&#45;&gt;A -->\n",
              "<g id=\"edge19\" class=\"edge\">\n",
              "<title>F&#45;&gt;A</title>\n",
              "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M205.78,-144.44C182.8,-162.77 149.71,-189.16 126.74,-207.47\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"207.95,-147.19 213.59,-138.22 203.59,-141.72 207.95,-147.19\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"124.7,-204.63 119.06,-213.6 129.06,-210.1 124.7,-204.63\"/>\n",
              "</g>\n",
              "<!-- E -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>E</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-170.15\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"27\" y=\"-165.1\" font-family=\"Times,serif\" font-size=\"14.00\">E</text>\n",
              "</g>\n",
              "<!-- F&#45;&gt;E -->\n",
              "<g id=\"edge11\" class=\"edge\">\n",
              "<title>F&#45;&gt;E</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M206.3,-129.23C170.28,-137.45 105.01,-152.35 63.94,-161.72\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"63.24,-158.29 54.27,-163.93 64.79,-165.12 63.24,-158.29\"/>\n",
              "</g>\n",
              "<!-- D -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>D</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-76.43\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"27\" y=\"-71.38\" font-family=\"Times,serif\" font-size=\"14.00\">D</text>\n",
              "</g>\n",
              "<!-- F&#45;&gt;D -->\n",
              "<g id=\"edge10\" class=\"edge\">\n",
              "<title>F&#45;&gt;D</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M206.3,-117.36C170.28,-109.14 105.01,-94.24 63.94,-84.86\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"64.79,-81.47 54.27,-82.66 63.24,-88.29 64.79,-81.47\"/>\n",
              "</g>\n",
              "<!-- G -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>G</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"100.27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"100.27\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">G</text>\n",
              "</g>\n",
              "<!-- F&#45;&gt;G -->\n",
              "<g id=\"edge12\" class=\"edge\">\n",
              "<title>F&#45;&gt;G</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M214.77,-109.31C192.28,-91.37 153.06,-60.09 126.88,-39.22\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"129.06,-36.48 119.06,-32.98 124.7,-41.95 129.06,-36.48\"/>\n",
              "</g>\n",
              "<!-- B -->\n",
              "<g id=\"node7\" class=\"node\">\n",
              "<title>B</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"191.64\" cy=\"-38.85\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"191.64\" y=\"-33.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n",
              "</g>\n",
              "<!-- F&#45;&gt;B -->\n",
              "<g id=\"edge9\" class=\"edge\">\n",
              "<title>F&#45;&gt;B</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M223.88,-105.8C218.43,-94.48 211.21,-79.49 204.99,-66.57\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"208.21,-65.18 200.71,-57.69 201.9,-68.22 208.21,-65.18\"/>\n",
              "</g>\n",
              "<!-- C -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>C</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"191.64\" cy=\"-207.73\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"191.64\" y=\"-202.68\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
              "</g>\n",
              "<!-- C&#45;&gt;F -->\n",
              "<g id=\"edge18\" class=\"edge\">\n",
              "<title>C&#45;&gt;F</title>\n",
              "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M205,-179.99C209.47,-170.7 214.46,-160.35 218.93,-151.06\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"201.91,-178.34 200.72,-188.87 208.22,-181.38 201.91,-178.34\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"222.05,-152.66 223.23,-142.13 215.74,-149.62 222.05,-152.66\"/>\n",
              "</g>\n",
              "<!-- C&#45;&gt;A -->\n",
              "<g id=\"edge17\" class=\"edge\">\n",
              "<title>C&#45;&gt;A</title>\n",
              "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M154.51,-216.2C148.89,-217.49 143.09,-218.81 137.46,-220.1\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"155.26,-219.62 164.23,-213.99 153.7,-212.8 155.26,-219.62\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"136.72,-216.68 127.75,-222.31 138.28,-223.5 136.72,-216.68\"/>\n",
              "</g>\n",
              "<!-- C&#45;&gt;E -->\n",
              "<g id=\"edge7\" class=\"edge\">\n",
              "<title>C&#45;&gt;E</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M165.92,-201.86C138.57,-195.62 95.07,-185.69 64.04,-178.61\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"64.82,-175.19 54.29,-176.38 63.26,-182.02 64.82,-175.19\"/>\n",
              "</g>\n",
              "<!-- C&#45;&gt;D -->\n",
              "<g id=\"edge6\" class=\"edge\">\n",
              "<title>C&#45;&gt;D</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M174.02,-193.68C145.06,-170.58 87.22,-124.46 53.36,-97.46\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"55.68,-94.83 45.68,-91.33 51.31,-100.3 55.68,-94.83\"/>\n",
              "</g>\n",
              "<!-- C&#45;&gt;G -->\n",
              "<g id=\"edge8\" class=\"edge\">\n",
              "<title>C&#45;&gt;G</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M183.21,-190.22C167.3,-157.18 132.74,-85.41 113.63,-45.75\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"116.83,-44.32 109.34,-36.83 110.53,-47.36 116.83,-44.32\"/>\n",
              "</g>\n",
              "<!-- C&#45;&gt;B -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>C&#45;&gt;B</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M191.64,-189.34C191.64,-160.28 191.64,-103.47 191.64,-68.58\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"195.14,-68.74 191.64,-58.74 188.14,-68.74 195.14,-68.74\"/>\n",
              "</g>\n",
              "<!-- A&#45;&gt;E -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>A&#45;&gt;E</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M82.91,-214.74C74.12,-207.73 63.27,-199.07 53.47,-191.26\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"55.68,-188.54 45.68,-185.05 51.31,-194.02 55.68,-188.54\"/>\n",
              "</g>\n",
              "<!-- A&#45;&gt;D -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>A&#45;&gt;D</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M91.87,-211.13C79.22,-184.88 55.2,-134.99 40.2,-103.85\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"43.46,-102.54 35.96,-95.05 37.15,-105.57 43.46,-102.54\"/>\n",
              "</g>\n",
              "<!-- A&#45;&gt;G -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>A&#45;&gt;G</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M100.27,-210.26C100.27,-173.86 100.27,-92.12 100.27,-47.85\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"103.77,-47.94 100.27,-37.94 96.77,-47.94 103.77,-47.94\"/>\n",
              "</g>\n",
              "<!-- A&#45;&gt;B -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>A&#45;&gt;B</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M108.7,-211.08C124.61,-178.04 159.18,-106.27 178.28,-66.6\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"181.39,-68.21 182.57,-57.69 175.08,-65.18 181.39,-68.21\"/>\n",
              "</g>\n",
              "<!-- E&#45;&gt;G -->\n",
              "<g id=\"edge16\" class=\"edge\">\n",
              "<title>E&#45;&gt;G</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M35.41,-152.7C48.05,-126.44 72.07,-76.56 87.07,-45.41\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"90.12,-47.14 91.31,-36.61 83.82,-44.1 90.12,-47.14\"/>\n",
              "</g>\n",
              "<!-- E&#45;&gt;B -->\n",
              "<g id=\"edge15\" class=\"edge\">\n",
              "<title>E&#45;&gt;B</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M44.62,-156.1C73.59,-133 131.42,-86.88 165.28,-59.88\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"167.33,-62.72 172.97,-53.75 162.96,-57.25 167.33,-62.72\"/>\n",
              "</g>\n",
              "<!-- D&#45;&gt;G -->\n",
              "<g id=\"edge14\" class=\"edge\">\n",
              "<title>D&#45;&gt;G</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M44.36,-62.59C53.15,-55.58 64.01,-46.92 73.81,-39.11\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"75.96,-41.87 81.6,-32.89 71.59,-36.39 75.96,-41.87\"/>\n",
              "</g>\n",
              "<!-- D&#45;&gt;B -->\n",
              "<g id=\"edge13\" class=\"edge\">\n",
              "<title>D&#45;&gt;B</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M52.73,-70.56C80.07,-64.32 123.57,-54.39 154.6,-47.31\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"155.38,-50.72 164.35,-45.08 153.82,-43.9 155.38,-50.72\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.sources.Source at 0x13230e1e0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_graph.plot(scale=1.5)\n",
        "# Note: Currently, if you add too many nodes with long names, it may throw an error.\n",
        "# In this case, try reducing the names of the nodes to 3 characters or less, or reduce the number of nodes in your graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTCqyhX8S4s4"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Complete the Structural Causal Model\n",
        "Now that you have defined the graph we have the variables and dependencies, but we still need to learn the relationships between these variables to understand the causal mechanisms at work.\n",
        "\n",
        "These relationships will be learned based on your data, so we will start by processing your data file. This happens in the following order:\n",
        "1. Load your data as a `DataFrame` object. If it is a csv file, you can just replace the filename in the code below and your data will be loaded properly. \n",
        "2. Once loaded, you can alter the data if needed before continuing with processing. The default processing functions will handle converting categorical data and other standard tasks, but if, for example, you want one of the features to be converted into binary value, you will have to do that here.\n",
        "3. Specify which features in your data have categorical values, and which have discrete values. The default data processing will assume that all discrete variables can be rounded to whole numbers. \n",
        "4. **Assign features**: As stated above, the nodes of your graph need not correspond to the corresponding data features. You will instead manually define that correspondance here, in the following format: \n",
        "    ```\n",
        "    assignments = {\n",
        "        'node_1': ['data_feature', 'data_feature', ...],\n",
        "        'node_2': ['data_feature', 'data_feature', ...],\n",
        "        ...\n",
        "    }\n",
        "    ```\n",
        "    If a node only has one corresponding feature, you would assign it like so: `'node': ['data_feature']`.\n",
        "\n",
        "    Assignments have the following restrictions:\n",
        "    * All nodes you assign must be present in the graph above, and every node in the graph must have an assignment. Empty assignments will not be accepted. \n",
        "    * Each data feature can only be assigned to a single node. \n",
        "    * Each data feature *must* be present in the `DataFrame` object you created in step (1). \n",
        "    It is ok if some of your data features are excluded from the model, but any excluded features will not be used in the subsequent causal analysis. \n",
        "\n",
        "*Note for later*: When doing your causal analysis later in this notebook, it may be easier if your \"protected attribute\"/\"X-value\"/\"input\" is binary. For example, in the \"special preprocessing\" in the code cell below, `'race'` is turned into a binary variable (0 for minority population, 1 for majority) so that later we can distinctly ask \"how does being a racial minority affect certain outcomes?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is okay to exclude features from the model but they will not be used in the causal analysis.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Hanita/causal/ci2-fairness-ncm/src/utilities.py:49: UserWarning: The following features were not assigned to any variable: {'compas_screening_date', 'decile_score', 'c_jail_out', 'id', 'r_charge_degree', 'v_score_text', 'event', 'violent_recid', 'c_charge_degree', 'v_screening_date', 'in_custody', 'r_charge_desc', 'c_jail_in', 'r_offense_date', 'name', 'vr_offense_date', 'start', 'end', 'c_case_number', 'decile_score.1', 'r_case_number', 'vr_charge_degree', 'r_days_from_arrest', 'out_custody', 'c_offense_date', 'screening_date', 'v_decile_score', 'type_of_assessment', 'first', 'vr_charge_desc', 'priors_count.1', 'vr_case_number', 'c_days_from_compas', 'c_charge_desc', 'r_jail_in', 'dob', 'v_type_of_assessment', 'age_cat', 'is_recid', 'days_b_screening_arrest', 'c_arrest_date', 'last', 'is_violent_recid', 'r_jail_out'}\n",
            "  warnings.warn('The following features were not assigned to any variable: {}'.format(unassigned_features), UserWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>race_orig</th>\n",
              "      <th>race</th>\n",
              "      <th>score_text_orig</th>\n",
              "      <th>score_text</th>\n",
              "      <th>age_orig</th>\n",
              "      <th>age</th>\n",
              "      <th>juv_fel_count_orig</th>\n",
              "      <th>juv_fel_count</th>\n",
              "      <th>juv_misd_count_orig</th>\n",
              "      <th>juv_misd_count</th>\n",
              "      <th>juv_other_count_orig</th>\n",
              "      <th>juv_other_count</th>\n",
              "      <th>priors_count_orig</th>\n",
              "      <th>priors_count</th>\n",
              "      <th>sex_orig</th>\n",
              "      <th>sex</th>\n",
              "      <th>two_year_recid_orig</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7095</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>0.5</td>\n",
              "      <td>40</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4350</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>0.5</td>\n",
              "      <td>32</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6769</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>High</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41</td>\n",
              "      <td>0.294872</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13</td>\n",
              "      <td>0.342105</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6472</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>High</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1606</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Medium</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      race_orig  race score_text_orig  score_text  age_orig       age  \\\n",
              "7095          1   1.0             Low         0.5        40  0.282051   \n",
              "4350          1   1.0             Low         0.5        32  0.179487   \n",
              "6769          0   0.0            High         0.0        41  0.294872   \n",
              "6472          0   0.0            High         0.0        32  0.179487   \n",
              "1606          0   0.0          Medium         1.0        36  0.230769   \n",
              "\n",
              "      juv_fel_count_orig  juv_fel_count  juv_misd_count_orig  juv_misd_count  \\\n",
              "7095                   0            0.0                    0             0.0   \n",
              "4350                   0            0.0                    0             0.0   \n",
              "6769                   0            0.0                    0             0.0   \n",
              "6472                   0            0.0                    0             0.0   \n",
              "1606                   0            0.0                    0             0.0   \n",
              "\n",
              "      juv_other_count_orig  juv_other_count  priors_count_orig  priors_count  \\\n",
              "7095                     0         0.000000                  0      0.000000   \n",
              "4350                     1         0.058824                  0      0.000000   \n",
              "6769                     0         0.000000                 13      0.342105   \n",
              "6472                     0         0.000000                  1      0.026316   \n",
              "1606                     0         0.000000                  0      0.000000   \n",
              "\n",
              "     sex_orig  sex  two_year_recid_orig  two_year_recid  \n",
              "7095     Male  1.0                    0             0.0  \n",
              "4350   Female  0.0                    0             0.0  \n",
              "6769     Male  1.0                    1             1.0  \n",
              "6472     Male  1.0                    0             0.0  \n",
              "1606     Male  1.0                    0             0.0  "
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the CSV file with your data:\n",
        "df = pd.read_csv('data/compas-scores-two-years.csv')\n",
        "\n",
        "# Do any special pre-processing that you may want to do (this is optional):\n",
        "df['race'] = df['race'].apply(lambda x: int(x=='Caucasian'))\n",
        "\n",
        "# Specify which features in your data are categorical, and which are discrete. \n",
        "# It is not necessary to specify features which you don't plan to use in your assignments, but it's fine if you do.\n",
        "categorical = ['race', 'age_cat', 'r_charge_degree', 'sex', 'score_text']\n",
        "discrete = ['juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'is_recid', 'two_year_recid']\n",
        "\n",
        "# Now define which columns of your data correspond to each node in your graph:\n",
        "assignments = {\n",
        "    'A': ['race'],\n",
        "    'B': ['score_text'],\n",
        "    'C': ['age'],\n",
        "    'D': ['juv_fel_count', 'juv_misd_count', 'juv_other_count'],\n",
        "    'E': ['priors_count'],\n",
        "    'F': ['sex'],\n",
        "    'G': ['two_year_recid']\n",
        "}\n",
        "\n",
        "# Process data & assignments\n",
        "my_data = process_data_assignments(df, assignments, my_graph, categorical, discrete)\n",
        "my_data.print_df(show_orig=True) # if you would like to compare to the pre-processed values, add the argument show_orig=True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When training the network, you are able to manually adjust various settings called \"hyperparameters\". These include the following:\n",
        "* `distribution`: which probability distribution should be used to generate values for unseen variables. Options include `uniform`, `bernoulli`, or `neural`. Default: `uniform` (this is recommended).\n",
        "* `nn`: the type of neural network to use to learn each relationship in your data. Options include `mlp` or `simple`. Default: `mlp` (this is recommended).\n",
        "* `n-epochs`: the number of epochs, or passes through the dataset to complete during the training phase, to run. Default: 10. \n",
        "* `device`: the device that this will be run with. Default: `cpu`.\n",
        "* `learning-rate`: how quickly the neural network should learn the distribution. Default: `1e-3`.\n",
        "* `optimizer`: the optimizer to use when computing and propagating the loss of each batch. Default: `torch.Adam`. \n",
        "\n",
        "You may set some, none, or all of these values manually. Valid definitions include:\n",
        "```\n",
        "hyperparameters = {\n",
        "    'distribution': 'bernoulli',\n",
        "    'n-epochs': 500\n",
        "}\n",
        "```\n",
        "```\n",
        "hyperparameters = {}\n",
        "```\n",
        "```\n",
        "hyperparameters = {\n",
        "    'n-epochs': 4600,\n",
        "    'learning-rate': 0.1,\n",
        "    'device': gpu\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Loss: 0.1459\n",
            "Epoch 2/2, Loss: 0.0867\n"
          ]
        }
      ],
      "source": [
        "# Set your parameters here:\n",
        "hyperparameters = {\n",
        "    'distribution': 'uniform',\n",
        "    'nn': 'mlp',\n",
        "    'device': 'cpu',\n",
        "    'n-epochs': 3,\n",
        "    'learning-rate': 1e-3,\n",
        "    'optimizer': None\n",
        "}\n",
        "\n",
        "# And train the model:\n",
        "my_model = get_ncm(my_graph, assignments, scale=my_data.get_assigned_scale())\n",
        "_ = train_ncm(my_model, my_data, hyperparameters=hyperparameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYOhC9bCTRMh"
      },
      "source": [
        "# Extract Causal Insights from the Model\n",
        "Now that you have a trained model, you can use it to evaluate cause-effect relationships in your data. The metrics that you can evaluate are split into three categories: (1) values that can be computed directly from the data, (2) values that would occur if you force a variable to take on a certain value, and (3) questions about what would have happened in an imaginary world where some observed facts are bluntly negated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observational Understanding\n",
        "Observational metrics can be calculated directly from the data. These include calculating standard probabilities and conditional probabilities (ex.: $P(Y=1)$ or $P(Y=1|X=0)$), as well as something called the \"total variation\".\n",
        "\n",
        "*Total Variation (TV)*: a measure of how much the probability distribution of some variable $Y$ is impacted by the observed value of a given attribute $X$. If possible values of $X$ are $x_0, x_1$ then the Total Variation can be calculated by the equation below.\n",
        "$$TV_{x_0,x_1}(y) = P(Y=y|X=x_1)-P(Y=y|X=x_0)$$\n",
        "\n",
        "The available observational measures are defined as follows:\n",
        "* `probability(model, variable, value, evidence)`: This will calculate the probability that a variable equals a certain value given the dictionary of evidence. The dictionary of conditional evidence is optional.\n",
        "    * `probability(model, 'Y',1)` will return $P(Y=1)$\n",
        "    * `probability(model, 'Y',1,{'X':0,'Z':2})` will return $P(Y=1|X=0,Z=2)$\n",
        "* `total_variation(model, variable, value, attr, aval1, aval0)` will return the total variation of the given variable relative to the given attribute. $TV_{aval0,aval1}(variable=value)$. `avail0` is an optional value, and will default to \"not avail1\" if left blank. \n",
        "    * `total_variation(model,'Y',1,'X',1,0)` will return $TV_{X=0,X=1}(Y=1) = P(Y=1|X=1)-P(Y=1|X=0)$\n",
        "    * `total_variation(model,'Y',1,'X',1)` will return $TV_{X\\neq 1,X=1}(Y=1) = P(Y=1|X=1)-P(Y=1|X\\neq 1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TV(G=1) = 0.2909 - 0.4644 = -0.1735\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "-0.17346282715099137"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_variation(my_model, 'G', 1, 'A', 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interventional Metrics\n",
        "Interventional metrics arise when you actively say \"what if we force this variable to take on a certain value?\"\n",
        "The difference between a conditional probability ($P(Y|X=x)$) and an interventional one ($P(Y|do(X=x))$) is that when you force an event to happen, you emancipate it from all other influences. [kinda stole this wording from the book of why but not exactly...]\n",
        "\n",
        "*For example*: say that patients who go to the doctor for a certain illness all recieve advice and prescription medication, and this allows them to heal within a week. Say that those who have not recieved the advice nor the medication don't heal so quickly.\n",
        "\n",
        "![](img/dr_advice_meds_healed.png)\n",
        "\n",
        "If we are trying to evaluate the likelihood that someone has healed, and we observe that they have recieved the advice, we can assume from our data that they went to the doctor and recieved medication too. \n",
        "\n",
        "Essentially, {patient got advice} $\\implies$ {patient went to doctor} $\\implies$ {patient got advice} AND {patient got medication}\n",
        "\n",
        "This means that $P(\\text{healed} | \\text{advice})=P(\\text{healed} | \\text{advice},\\text{medication})$.\n",
        "\n",
        "But what if a patient hears the doctor's advice from a friend? In this case, even though the patient has heard the advice, they may not have seen the doctor, and they may not have access to the medication. This is an example of an intervention. Although we can usually assume that someone who has heard the advice has seen a doctor, the friend intervened and gave the patient advice, so even though we know the patient has heard the advice, we don't have any knowledge of whether or not they went to a doctor and recieved medication. Here, $P(\\text{healed} | do(\\text{advice}))\\neq P(\\text{healed} | \\text{advice})$.\n",
        "\n",
        "*Total Effect (TE)*: Similar to Total Variation, except these variations represent changes in behavior based on the value of $X$, rather than comparing the naturally arising distribution based on $X$. \n",
        "\n",
        "$$TE_{x_0,x_1}(y) = P(Y=y | do(X=x_1)) - P(Y=y | do(X=x_0))$$\n",
        "\n",
        "*z-Total Effect (z-TE)*: Total Effect with an additional observational condition. We intervene to force $X=\\{some-value\\}$, and we add the condition that some other variable $Z$ was observed to be $z$. \n",
        "\n",
        "$$z\\text{-}TE_{x_0,x_1}(y) = P(Y=y | do(X=x_1), Z=z) - P(Y=y | do(X=x_0), Z=z)$$\n",
        "\n",
        "The available interventional measures are defined as follows:\n",
        "* `probability(model,variable, value, evidence, intervention)`: This will calculate the probability that a variable equals a certain value given the dictionary of evidence, and the dictionary of interventions. Both dictionaries are optional.\n",
        "    * `probability(model,'Y',1,{'X':0},{'Z':1})` will return $P(Y=1 | X=0, do(Z=1))$\n",
        "    * `probability(model,'Y',1,intervention={'Z':1})` will return $P(Y=1 | do(Z=1))$\n",
        "* `total_effect(model, variable, value, attr, aval1, aval0, evidence)` \n",
        "    * `total_effect(model, 'Y', 1, 'X', 1, 0)` will return $TE_{0,1}(Y=1) = P(Y=1 | do(X=1)) - P(Y=1 | do(X=0))$\n",
        "    * `total_effect(model, 'Y', 1, 'X', 1, 0, evidence={Z:z})` will return $z$-$TE_{0,1}(Y=1) = P(Y=1 | do(X=1),Z=z) - P(Y=1 | do(X=0),Z=z)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TE(G=1) = 0.2728 - 0.4617 = -0.1889\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "-0.1889"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_effect(my_model, 'G', 1, 'A', 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What-if?: Quantifying the Imaginary \n",
        "To fully answer questions about *why* certain phenomina occur in our data, we need to be able to ask \"what would have happened if things had been different?\" thereby computing the probability of something which, by definition, could not have happened. These questions are called \"counterfactuals,\" because they require analyzing circumstances which factually did not occur.\n",
        "\n",
        "For example, say people have the option to take a medication or heal naturally, and that the observational data shows that individuals who healed naturally actually survived longer on average. Is this because the medication was harmful, or is it because the *types* of people who decided to heal naturally were typically younger, healthier, had fewer comorbidities, or had fewer symptoms to begin with? \n",
        "\n",
        "What is the probability that someone who opted out of medication would have healed had they taken it? What is the probability that someone who decided to take medication would have healed if they never got it? \n",
        "\n",
        "These are \"counterfactual\" questions because to answer them we would have to go back in time and change history. There is no experiment that can deny treatment to an already treated person and compare the two outcomes. \n",
        "\n",
        "#### New notation: $P(Y_X)$\n",
        "\n",
        "$P(Y_{X=x})$ is the same as saying \"probability of $Y$ intervened on to force $X=x$\". In the section above, this was denoted $P(Y|do(X=x))$. However when written with this notation, we are stating that the intervention $do(X=x)$ only applies to $Y$. \n",
        "\n",
        "If another variable in the model, $Z$, is also affected by $X$, then when calculating $P(Y|do(X=x),Z=z)$, the intervention $X=x$ will be applied to both $Y$ and $Z$. Conversely, when evaluating the term $P(Y_{X=x}|Z=z)$, the intervention is only applied to $Y$, and $Z$ will be calculated based on the unaffected/real $X$ values. \n",
        "\n",
        "#### Counterfactual Quantities:\n",
        "\n",
        "*Effect of Treatment on the Treated (ETT)*: evaluate whether people who gained access to treatment would have had the same outcome if they had never recieved it.\n",
        "$$ETT_{x,x'}(Y)=P(Y_{X=x}=y | X=x')$$\n",
        "\n",
        "*Probability of Necessity (PN)*: encodes how much the presence of a value $X$ was a *necessary* cause to make $Y=1$.\n",
        "$$PN(X;Y)=P(Y_{X=0}=0|X=1,Y=1)$$\n",
        "\n",
        "*Probability of Sufficiency (PS)*: encodes how much the presence of a value $X$ was *sufficient* to make $Y=1$.\n",
        "$$PS(X;Y)=P(Y_{X=1}=1|X=0,Y=0)$$\n",
        "\n",
        "Both of the above translate to \"in a situation where $X=x$ and $Y=y$, what is the probability that the value of $Y$ would have been different if you had changed the value of $X$?\" These can be combined into \n",
        "$$PN/PS_{(x,y)(x',y')}(X;Y) = P(Y_{X=x}=y | X=x', Y=y')$$\n",
        "\n",
        "\n",
        "The available counterfactual measures are defined as follows:\n",
        "* `ett(model, outcome_var, outcome_val, treatment_var, treatment_vals={'actual':_, 'whatif':_})`: This will calculate the probability of a given outcome if we had intervened to change the treatment. In the `treatment_vals` dictionary, you must specify either `actual` or `whatif`, but you do not need to specify both. \n",
        "  * `ett(model, 'Y',1,'X',{'actual':0, 'whatif':1})` will return $P(Y_{X=1}=1|X=0)$, which is the probability that $Y=1$ if we had intervened to make $X=1$, given that $X$ was actually 0.\n",
        "  * `ett(model, 'Y',1,'X',{'whatif':1})` will return $P(Y_{X=1}=1|X\\neq 1)$, which is the probability that $Y=1$ if we had intervened to make $X=1$, given that $X$ was not actually 1.\n",
        "  * Note: the \"whatif\" value must be specified so `treatment_vals={'actual':_}` is not a valid input.\n",
        "\n",
        "* `pnps(model, outcome_var, outcome_vals={'actual':_, 'whatif':_}, treatment_var, treatment_vals={'actual':_, 'whatif':_})` \n",
        "  * `pnps(model, 'Y', outcome_vals={'actual':0, 'whatif':1}, 'X', treatment_vals={'actual':0, 'whatif':1})` will return the probability that $Y=1$ if we had intervened to make $X=1$, given that $Y$ and $X$ were actually both 0. \n",
        "  * Note: like with ETT, the \"whatif\" values must be explicitly stated in both `outcome_vals` and `treatment_vals`, but the \"actual\" values may be assumed. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0000: probability that B=0 if we had intervened to make A=1, given that B was not actually 0 and A was actually 0.\n",
            "0.4151: probability that G=0 if we had intervened to make A=1, given that G was not actually 0 and A was actually 0.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.41511811023622047"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outcome_vals = {\n",
        "    'whatif': 0\n",
        "}\n",
        "treatment_vals = {\n",
        "    'actual': 0,\n",
        "    'whatif': 1\n",
        "}\n",
        "\n",
        "pnps(my_model, 'B', outcome_vals, 'A', treatment_vals, assignments)\n",
        "pnps(my_model, 'G', outcome_vals, 'A', treatment_vals, assignments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2575: probability that B=1 if we had intervened to make A=1, given that A was actually 0.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.25750144258511254"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ett(my_model, 'B', 1, 'A', treatment_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tv0OBYGTF5U"
      },
      "source": [
        "# Project onto the Standard Fairness Model\n",
        "\n",
        "The standard fairness model (SFM) is a model whose graph has four nodes:\n",
        "* $X$: The protected attribute. When doing fairness analysis, we are trying to figure out whether or not an outcome is fair with respect to this attribute. (Ex.: race)\n",
        "* $Z$: The counfounding variables. These variables are not causally influenced by the protected attribute $X$, but may be correlated in some way. (Ex.: demographic information, zip code)\n",
        "* $W$: The mediator variables. Variables which may be causally influenced by the protected attribute. (Ex.: education-level, prior employment)\n",
        "* $Y$: The outcome variable. (Ex.: admissions, hiring decisions, salary)\n",
        "\n",
        "When projecting onto the SFM, you should select one of your model's variables to be $X$ and one to be $Y$, but you may assign multiple variables as confounders or mediators. Counfounders may have any relationship to the other confounders, and mediators may have any relationship with the other mediators, however there is a specific structure that must exist between $X$, $Z$, $W$, and $Y$:\n",
        "* $Y$ must be a variable that has 0 arrows pointing toward $X$, $Z$, or $W$.\n",
        "* $W$ must contain variables that have 0 arrows pointing toward $X$ or $Z$.\n",
        "* $X$ and $Z$ cannot have arrows pointing towards each other, but they may have a bidirected arrow between them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Here is an example**:\n",
        "Given the following graph. \n",
        "\n",
        "![example1graph.png](img/example1graph.png)\n",
        "\n",
        "Based on this graph, you could do either of the following projections:\n",
        "```\n",
        "projection1 = {\n",
        "    'X': 'e',\n",
        "    'Z': ['a', 'b'],\n",
        "    'W': ['c', 'd'],\n",
        "    'Y': 'f'\n",
        "}\n",
        "```\n",
        "\n",
        "or \n",
        "```\n",
        "projection2 = {\n",
        "    'X': 'a',\n",
        "    'Z': ['e'],\n",
        "    'W': ['b', 'c', 'd'],\n",
        "    'Y': 'f'\n",
        "}\n",
        "```\n",
        "<img src=\"img/ex1projection1.png\" alt=\"ex1p1\" style=\"width: 300px;\"/><img src=\"img/ex1projection2.png\" alt=\"ex1p2\" style=\"width: 300px;\"/>\n",
        "\n",
        "You could also do a partial projection:\n",
        "```\n",
        "partial_projection = {\n",
        "    'X': 'a',\n",
        "    'Z': ['e'],\n",
        "    'Y': 'b'\n",
        "}\n",
        "```\n",
        "\n",
        "<img src=\"img/partialprojection.png\" alt=\"ex1partial\" style=\"width: 300px;\"/>\n",
        "\n",
        "The following would **not** be a valid projection: \n",
        "```\n",
        "bad_projection = {\n",
        "    'X': 'a',\n",
        "    'Z': ['b', 'e'],\n",
        "    'W': ['c', 'd'],\n",
        "    'Y': 'f'\n",
        "}\n",
        "```\n",
        "<img src=\"img/ex1bad.png\" alt=\"ex1bad\" style=\"width: 300px;\"/>\n",
        "\n",
        "because there is an arrow from the `X` variable (containing `'a'`) to the `Z` variable (containing `'b'`). This indicates that `X` may actually cause `Z`, rather than just being confounded with `Z`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### <span style=\"text-decoration:underline\">Summary of Projection Requirements:</span>\n",
        "* You *must* define an $X$ and $Y$, but $Z$ and $W$ are optional. \n",
        "* $X$ and $Y$ represent one variable each, but $Z$ and $W$ may be a list of values.\n",
        "* You are projecting the nodes of your *graph* onto the nodes of the SFM ($\\{X,Z,W,Y\\}$). Do not try to project your data features directly onto the SFM.\n",
        "* You do not have to project every node from your graph onto the SFM, however you should not leave out nodes that are along paths between nodes that are within the SFM. \n",
        "    * For example, if you have a graph with the path $A\\rightarrow B\\rightarrow C$, and you project this onto the SFM such that `Z=['B','C']`, you have the option to set `A` one of the `Z` values or leave it out of your projection entirely. However if you want to set `Z=['A','C']`, then you need to add `B`, so that `Z=['A','B','C']` instead.\n",
        "* There can be bidirected arrows between X and Z, but there cannot be any bidirected arrow paths between X and W or Y, nor between Z and W or Y, nor between W and Y. \n",
        "* Reiterating the directed path rules:\n",
        "    * There cannot be any directed paths from any of the other variables in your projection (Z,W,Y) to the variable being projected onto X.\n",
        "    * There cannot be any directed paths from the X, W, or Y variables to any of the variables being projected onto Z. \n",
        "    * There cannot be any directed paths from the variable being projected onto Y to any of the other variables in your projection (X,Z,W)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Protected Attribute: ['race']\n",
            "Confounders:         ['age', 'sex']\n",
            "Mediators:           ['priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count']\n",
            "Outcome:             ['two_year_recid']\n"
          ]
        }
      ],
      "source": [
        "# Specify your projection here:\n",
        "projection = {\n",
        "    'X': 'A',\n",
        "    'Z': ['C', 'F'],\n",
        "    'W': ['E', 'D'],\n",
        "    'Y': 'G'\n",
        "}\n",
        "\n",
        "sfm = project_to_sfm(my_model, projection, my_data, my_graph) \n",
        "# Ensure this was the projection you were expecting:\n",
        "sfm.print_projection()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NATPdYARTaaq"
      },
      "source": [
        "# Run Fairness Tasks\n",
        "\n",
        "(This will have a lot of the same tasks & suggestions as Drago's git helper https://dplecko.github.io/CFA/)\n",
        "\n",
        "Most fairness analysis can be split into three general tasks: (1) bias detection and quantification, (2) fair prediction, and (3) fair decision-making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1: Bias Detection & Quantification\n",
        "Here we will evaluate \"fairness measures\" which can determine whether discrimination is present within a dataset, and indicate how strong that discrimination is.\n",
        "\n",
        "1. *Direct Effect (DE)* indicates whether your protected attribute *X* is directly impacting your outcome variable *Y*. \n",
        "\n",
        "2. *Indirect Effect (IE)* indicates whether your outcome variable is being indirectly impacted by your protected attribute. \n",
        "\n",
        "For example, if *X* denotes race and *Y* denotes whether a candidate was hired, \"direct effect\" would indicate whether two identical candidates of different races would have the same likelihood of being hired, whereas \"indirect effect\" would indicate that a candidate's race impacts some other attribute (like education level, prior job experience, etc.) which in turn impacts salary.\n",
        "\n",
        "3. *Spurious Effect (SE)* indicates whether there are variables that causally affect both your outcome variable and protected attribute, causing them to be correlated. \n",
        "\n",
        "Race causally affects an individual's hair color (if they are not of European descent, then there is an incredibly high likelihood that they will have black hair). If race also affects whether a candidate is hired (directly or indirectly), then there will be a spurious effect of hair color on salary, even though hair color itself does not directly or indirectly impact a candidate's salary. \n",
        "\n",
        "When thinking about bias, we typically think about how some attribute $X$ impacts a decision or prediction $Y$. If the direct effect is non-zero, then there is evidence of disparate *treatment* in the outcome $Y$, meaning $X$ is being used in the decision process. \n",
        "\n",
        "If the indirect or spurious effects are non-zero, then there is evidence of disparate *impact*, which typically refers to cases where discrimination is unintended or implicit. Sometimes it is not possible to eliminate disparate impact. For example, if there is discrimination in the educational system, and a job requires a certain level of education, then they may hire more people of a certain demographic simply because more people from that demographic have the necessary qualifications. This is known as *business necessity*. \n",
        "\n",
        "The `fairness_cookbook` below will calculate bias detection information based on the Standard Fairness Model projection you created above. Note that you will need to define an $x_0$ and $x_1$ value, just like you did when calculating the $ETT$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xDE^sym = -0.4482¬±0.0207\t hypothesis \"no direct effect\" REJECTED\n",
            "\t ---> evidence of disperate TREATMENT.\n",
            "xIE^sym = -0.0542¬±0.0207\t hypothesis \"no indirect effect\" REJECTED\n",
            "xSE_x1x0 = -0.0066¬±0.0162\t hypothesis \"no spurious effect\" ACCEPTED\n",
            "\t ---> evidence of disperate IMPACT.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create your cookbook\n",
        "fcb = FairnessCookbook(sfm=sfm, x0_val=0, x1_val=1)\n",
        "\n",
        "# Get your data:\n",
        "fcb.fairness_cookbook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'TE': -0.2518,\n",
              " 'DE': -0.22694999999999999,\n",
              " 'DEx0x1': -0.2279,\n",
              " 'DEx1x0': 0.226,\n",
              " 'IE': -0.024849999999999997,\n",
              " 'IEx0x1': -0.02579999999999999,\n",
              " 'IEx1x0': 0.023900000000000005,\n",
              " 'exp-SEx0': -0.0037131963536391477,\n",
              " 'exp-SEx1': 0.01213081903528651}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fairness_cookbook(sfm, X=sfm.X, Z=sfm.Z, W=sfm.W, Y=sfm.Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2: Fair Prediction \n",
        "The goal of \"Fair Prediction\" tasks is to construct a predictor $\\hat{Y}$ of $Y$, which is also a function of $X$, $Z$, and $W$, but does not carry over any bias from the existing data. This is achieved by ensuring $\\hat{Y}$ satisfies some kind of \"fairness constraint\". \n",
        "\n",
        "As stated above, these predictors don't always have to be \"fair\" with respect to every single attribute. For example, say a hospital is building a predictor to scan through applications and predict whether the candidate will be a good Doctor. They will likely include education status as a mediator variable, however the predictor should not be \"fair\" with respect to educational status. While gender bias and racial discrimination should be eliminated from the model, the hospital needs to maintain a strict bias against anyone who has not completed medical school. This is what's known as a \"Business Necessity\".\n",
        "\n",
        "When coming up with fair predictors, we will need to first define a \"Business Necessity\" set, which in our case just refers to the set of variables for which bias should not be eliminated. When using the standard fairness model (which we are), the allowed business necessity sets are: {$Z$}, {$W$}, {$Z,W$}, or none."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.1944039762020111], [-0.1929091215133667], [-0.19475318491458893], [-0.1945362389087677], [-0.17529477179050446], [-0.17523501813411713], [-0.18882668018341064], [-0.19463416934013367], [-0.1942187249660492], [-0.19469603896141052], [-0.19464845955371857], [-0.19479742646217346], [-0.18791690468788147], [-0.1719491183757782], [-0.18887841701507568], [-0.18894661962985992], [-0.1945430189371109], [-0.18894141912460327], [-0.18885020911693573], [-0.19412128627300262], [-0.19443634152412415], [-0.19308102130889893], [-0.187122642993927], [-0.18837526440620422], [-0.1946844458580017], [-0.18895608186721802], [-0.1889631450176239], [-0.18861708045005798], [-0.1943487823009491], [-0.1904839277267456], [-0.1913701295852661], [-0.19429321587085724], [-0.17283184826374054], [-0.19423209130764008], [-0.18917495012283325], [-0.1943800151348114], [-0.1945013403892517], [-0.19437256455421448], [-0.19340303540229797], [-0.1918158233165741], [-0.1888360232114792], [-0.18894065916538239], [-0.1946164071559906], [-0.19438618421554565], [-0.19449204206466675], [-0.19436414539813995], [-0.194374680519104], [-0.19365932047367096], [-0.1934753656387329], [-0.18861013650894165], [-0.19462844729423523], [-0.18863874673843384], [-0.18786829710006714], [-0.19479583203792572], [-0.18892641365528107], [-0.19376346468925476], [-0.19228309392929077], [-0.1943402886390686], [-0.19477948546409607], [-0.1938619762659073], [-0.18890157341957092], [-0.19149762392044067], [-0.19428099691867828], [-0.1943804919719696], [-0.19347485899925232], [-0.19455716013908386], [-0.1947682946920395], [-0.18908829987049103], [-0.18893878161907196], [-0.19386012852191925], [-0.19441071152687073], [-0.19454115629196167], [-0.19457708299160004], [-0.1920471042394638], [-0.194672629237175], [-0.19391044974327087], [-0.18894848227500916], [-0.18778207898139954], [-0.1890125870704651], [-0.18784482777118683], [-0.19253931939601898], [-0.19473549723625183], [-0.1944378912448883], [-0.1948007047176361], [-0.17611737549304962], [-0.17604508996009827], [-0.1947866678237915], [-0.1726483702659607], [-0.1947261393070221], [-0.18923863768577576], [-0.1947261095046997], [-0.18769100308418274], [-0.18566294014453888], [-0.19478940963745117], [-0.1947130262851715], [-0.1888483762741089], [-0.19381201267242432], [-0.19173069298267365], [-0.18883869051933289], [-0.1735486090183258]]\n"
          ]
        }
      ],
      "source": [
        "fair_pred = fair_predictions(my_data, sfm, x0=0, x1=1, bn='')\n",
        "\n",
        "# You can now obtain predictions on new data\n",
        "preds = sfm.predict()\n",
        "print(preds.tolist())\n",
        "\n",
        "# And decompose the predictions on the evaluation set\n",
        "faircause_decomposition = fairness_cookbook(sfm, X=sfm.X, Z=sfm.Z, W=sfm.W, Y='fair_predictions', x0=0, x1=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOoTiWA3cC9RHRSH13/DGw1",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
